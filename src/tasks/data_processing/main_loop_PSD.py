import cvxpy as cp
import numpy as np
import os
import pandas as pd
from src.tasks.pre_processing.settings import Settings
from src.utils import ErrorHandler, ErrorCode, ErrorLevel
from src.helpers.xplor_maker import make_xplor


def load_previous_result(filepath: str) -> np.ndarray | None:
    """
    å‰å›ã®è¨ˆç®—çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
    
    Args:
        filepath: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        èª­ã¿è¾¼ã‚“ã è¡Œåˆ—ï¼ˆnumpyé…åˆ—ï¼‰ã€å¤±æ•—æ™‚ã¯None
    """
    try:
        if not os.path.exists(filepath):
            return None
            
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
        df = pd.read_csv(filepath, header=None)
        matrix = df.values
        
        # æ­£æ–¹è¡Œåˆ—ã‹ãƒã‚§ãƒƒã‚¯
        if matrix.shape[0] != matrix.shape[1]:
            print(f"è­¦å‘Š: èª­ã¿è¾¼ã‚“ã è¡Œåˆ—ãŒæ­£æ–¹è¡Œåˆ—ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚å½¢çŠ¶: {matrix.shape}")
            return None
            
        # æ•°å€¤å‹ã«å¤‰æ›
        matrix = matrix.astype(np.float64)
        
        # NaNã‚„ç„¡é™å¤§ã®å€¤ã‚’ãƒã‚§ãƒƒã‚¯
        if not np.isfinite(matrix).all():
            print("è­¦å‘Š: èª­ã¿è¾¼ã‚“ã è¡Œåˆ—ã«ç„¡åŠ¹ãªå€¤ï¼ˆNaN/Infï¼‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
            return None
            
        print(f"å‰å›ã®çµæœã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {filepath}, å½¢çŠ¶: {matrix.shape}")
        return matrix
        
    except pd.errors.EmptyDataError:
        print(f"ã‚¨ãƒ©ãƒ¼: CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒç©ºã§ã™: {filepath}")
        return None
    except pd.errors.ParserError as e:
        print(f"ã‚¨ãƒ©ãƒ¼: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {filepath}, {e}")
        return None
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {filepath}, {e}")
        return None


def improve_objective_scaling(target_data: np.ndarray, weights: np.ndarray) -> tuple[float, float]:
    """
    ç›®çš„é–¢æ•°ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’æ”¹å–„ã™ã‚‹ãŸã‚ã®ã‚¹ã‚±ãƒ¼ãƒ«å› å­ã‚’è¨ˆç®—
    
    Args:
        target_data: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
        weights: é‡ã¿è¡Œåˆ—
        
    Returns:
        tuple[float, float]: (data_scale, weight_scale)
    """
    # ãƒ‡ãƒ¼ã‚¿ã®å…¸å‹çš„ãªã‚¹ã‚±ãƒ¼ãƒ«ã‚’è¨ˆç®—
    data_scale = np.sqrt(np.mean(target_data ** 2))
    
    # é‡ã¿ã®å…¸å‹çš„ãªã‚¹ã‚±ãƒ¼ãƒ«ã‚’è¨ˆç®—
    weight_scale = np.sqrt(np.mean(weights))
    
    # ã‚¹ã‚±ãƒ¼ãƒ«ãŒå°ã•ã™ãã‚‹å ´åˆã®èª¿æ•´
    if data_scale < 1e-6:
        data_scale = 1e-3
    if weight_scale < 1e-6:
        weight_scale = 1.0
        
    print(f"Data scale: {data_scale:.2e}, Weight scale: {weight_scale:.2e}")
    return data_scale, weight_scale


def main_loop_cvxpy(
    basis: np.ndarray, 
    target_data: np.ndarray, 
    settings: Settings,
    weights: np.ndarray = None,
    regularization_lambda: float = 0.0,
    initial_P: np.ndarray = None,
    initial_method: str = "identity",  # "identity", "random", "file"
    initial_scale: float = 1.0,
    target_mse: float = 1e-3,  # ç›®æ¨™MSEï¼ˆã“ã‚Œä»¥ä¸‹ãªã‚‰ååˆ†ï¼‰
    target_relative_error: float = 5e-2,  # ç›®æ¨™ç›¸å¯¾èª¤å·®ï¼ˆã“ã‚Œä»¥ä¸‹ãªã‚‰ååˆ†ï¼‰
    zero_constraints: list[tuple[int, int]] = None  # ã‚¼ãƒ­åˆ¶ç´„: [(i,j), ...] ã®ãƒªã‚¹ãƒˆ
) -> None:
    """
    CVXPYã‚’ç”¨ã„ã¦åŠæ­£å®šå€¤åˆ¶ç´„ä»˜ãã®æœ€é©åŒ–å•é¡Œã‚’è§£ã
    
    Args:
        basis: nÃ—nÃ—grid_xÃ—grid_yÃ—grid_z ã®åŸºåº•é–¢æ•°é…åˆ—
        target_data: grid_xÃ—grid_yÃ—grid_z ã®ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
        settings: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        weights: é‡ã¿è¡Œåˆ—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å…¨ã¦1ï¼‰
        regularization_lambda: æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯0ï¼‰
        initial_P: åˆæœŸå€¤è¡Œåˆ—
        initial_method: åˆæœŸå€¤ã®ç”Ÿæˆæ–¹æ³• ("identity", "random", "file")
        initial_scale: åˆæœŸå€¤ã®ã‚¹ã‚±ãƒ¼ãƒ«
        target_mse: ç›®æ¨™MSEï¼ˆã“ã‚Œä»¥ä¸‹ãªã‚‰ååˆ†ï¼‰
        target_relative_error: ç›®æ¨™ç›¸å¯¾èª¤å·®ï¼ˆã“ã‚Œä»¥ä¸‹ãªã‚‰ååˆ†ï¼‰
        zero_constraints: 0ã«å›ºå®šã™ã‚‹æˆåˆ†ã®ãƒªã‚¹ãƒˆ [(i,j), ...] 
                         ä¾‹: [(0,3), (3,0), (1,4), (4,1)] ã§ç‰¹å®šã®æ··æˆã‚’ç¦æ­¢
    
    Returns:
        Noneï¼ˆçµæœã¯ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã•ã‚Œã‚‹ï¼‰
    """
    error_handler = ErrorHandler()
    
    try:
        # å…¥åŠ›æ¤œè¨¼
        if basis.ndim != 5:
            error = error_handler.handle(
                f"basisã¯5æ¬¡å…ƒé…åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ç¾åœ¨ã®æ¬¡å…ƒ: {basis.ndim}",
                ErrorCode.INVALID_INPUT,
                ErrorLevel.CRITICAL
            )
            if error:
                raise error
                
        if target_data.ndim != 3:
            error = error_handler.handle(
                f"target_dataã¯3æ¬¡å…ƒé…åˆ—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ç¾åœ¨ã®æ¬¡å…ƒ: {target_data.ndim}",
                ErrorCode.INVALID_INPUT,
                ErrorLevel.CRITICAL
            )
            if error:
                raise error
        
        n = basis.shape[0]
        grid_shape = target_data.shape
        
        if basis.shape[1] != n:
            error = error_handler.handle(
                "basisã®æœ€åˆã®2æ¬¡å…ƒã¯åŒã˜ã‚µã‚¤ã‚ºã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™",
                ErrorCode.INVALID_INPUT,
                ErrorLevel.CRITICAL
            )
            if error:
                raise error
                
        if basis.shape[2:] != grid_shape:
            error = error_handler.handle(
                f"basisã®gridéƒ¨åˆ†ã¨target_dataã®å½¢çŠ¶ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚basis: {basis.shape[2:]}, target: {grid_shape}",
                ErrorCode.INVALID_INPUT,
                ErrorLevel.CRITICAL
            )
            if error:
                raise error
        
        # é‡ã¿è¡Œåˆ—ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        if weights is None:
            weights = np.ones(grid_shape)
        elif weights.shape != grid_shape:
            error_handler.handle(
                f"é‡ã¿è¡Œåˆ—ã®å½¢çŠ¶ãŒtarget_dataã¨ä¸€è‡´ã—ã¾ã›ã‚“ã€‚weights: {weights.shape}, target: {grid_shape}",
                ErrorCode.INVALID_INPUT,
                ErrorLevel.WARNING
            )
            weights = np.ones(grid_shape)
        
        print(f"æœ€é©åŒ–é–‹å§‹: n={n}, grid_shape={grid_shape}")
        
        # ã‚¼ãƒ­åˆ¶ç´„ã®æ¤œè¨¼ã¨ãƒ­ã‚°å‡ºåŠ›
        if zero_constraints is not None:
            print(f"ã‚¼ãƒ­åˆ¶ç´„ãŒæŒ‡å®šã•ã‚Œã¾ã—ãŸ: {len(zero_constraints)}å€‹ã®æˆåˆ†")
            for i, (row, col) in enumerate(zero_constraints):
                if not (0 <= row < n and 0 <= col < n):
                    error = error_handler.handle(
                        f"ã‚¼ãƒ­åˆ¶ç´„ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒç¯„å›²å¤–ã§ã™: ({row}, {col}), æœ‰åŠ¹ç¯„å›²: [0, {n-1}]",
                        ErrorCode.INVALID_INPUT,
                        ErrorLevel.CRITICAL
                    )
                    if error:
                        raise error
                print(f"  åˆ¶ç´„ {i+1}: P[{row}, {col}] = 0")
                
                # ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆæ€§ã®ç¢ºä¿ï¼šP[i,j] = 0 ãªã‚‰ P[j,i]* = 0 ã‚‚è‡ªå‹•è¿½åŠ 
                if row != col and (col, row) not in zero_constraints:
                    zero_constraints.append((col, row))
                    print(f"  ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆæ€§ã«ã‚ˆã‚Šè¿½åŠ : P[{col}, {row}] = 0")
        
        # CVXPYã®å¤‰æ•°å®šç¾©ï¼ˆnÃ—n ã®è¤‡ç´ ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆåŠæ­£å®šå€¤è¡Œåˆ—Pï¼‰
        P = cp.Variable((n, n), hermitian=True)
        
        # åˆæœŸå€¤ã®è¨­å®š
        if initial_P is None or initial_P.shape != (n, n):
            if initial_method == "identity":
                initial_P = initial_scale * np.eye(n, dtype=complex)
            elif initial_method == "random":
                # è¤‡ç´ æ•°ã®ä½ãƒ©ãƒ³ã‚¯è¡Œåˆ—ã‚’ç”Ÿæˆã—ã¦ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆåŒ–
                A_real = np.random.randn(n, min(n, 4))
                A_imag = np.random.randn(n, min(n, 4))
                A = A_real + 1j * A_imag
                initial_P = initial_scale * (A @ A.conj().T)
            elif initial_method == "file":
                initial_P = load_previous_result("output/matrix.csv")
                if initial_P is None:
                    initial_P = np.eye(n, dtype=complex)
                    error_handler.handle(
                        "å‰å›ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã€‚å˜ä½è¡Œåˆ—ã‚’ä½¿ç”¨ã—ã¾ã™",
                        ErrorCode.NOT_FOUND,
                        ErrorLevel.WARNING
                    )
                else:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚“ã å®Ÿæ•°è¡Œåˆ—ã‚’è¤‡ç´ æ•°ã«å¤‰æ›
                    initial_P = initial_P.astype(complex)
        
        # åˆæœŸå€¤ã®æ¤œè¨¼ã¨è¨­å®š
        if initial_P is not None:
            # å½¢çŠ¶ãƒã‚§ãƒƒã‚¯
            if initial_P.shape != (n, n):
                error_handler.handle(
                    f"åˆæœŸå€¤ã®å½¢çŠ¶ãŒä¸æ­£ã§ã™ã€‚expected: ({n}, {n}), got: {initial_P.shape}",
                    ErrorCode.INVALID_INPUT,
                    ErrorLevel.WARNING
                )
                initial_P = np.eye(n, dtype=complex)
            
            # ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆæ€§ã®ç¢ºä¿
            initial_P = (initial_P + initial_P.conj().T) / 2
            
            # åŠæ­£å®šå€¤æ€§ã®ç¢ºä¿
            eigenvals, eigenvecs = np.linalg.eigh(initial_P)
            eigenvals_clipped = np.maximum(eigenvals, 1e-10)
            initial_P = eigenvecs @ np.diag(eigenvals_clipped) @ eigenvecs.conj().T
            
            # åˆæœŸå€¤ã‚’è¨­å®š
            P.value = initial_P
            print(f"åˆæœŸå€¤è¨­å®šå®Œäº†:")
            print(f"  - ãƒˆãƒ¬ãƒ¼ã‚¹: {np.trace(initial_P):.6f}")
            print(f"  - æœ€å°å›ºæœ‰å€¤: {np.min(eigenvals_clipped):.2e}")
            print(f"  - ãƒ•ãƒ­ãƒ™ãƒ‹ã‚¦ã‚¹ãƒãƒ«ãƒ : {np.linalg.norm(initial_P, 'fro'):.6f}")
            print(f"  - è¤‡ç´ æ•°å¯¾å¿œ: True")
        
        # ç›®çš„é–¢æ•°ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æ”¹å–„
        data_scale, weight_scale = improve_objective_scaling(target_data, weights)
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã‚ŒãŸé‡ã¿ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
        scaled_weights = weights / weight_scale
        scaled_target = target_data / data_scale
        
        # å·®åˆ†è¨ˆç®—ç”¨ã®å¤‰æ•°
        rho_diff = cp.Variable(grid_shape)
        
        # åˆ¶ç´„æ¡ä»¶: rho_diff = sum_{i,j} P[i,j] * basis[i,j,:,:,:] - scaled_target
        constraints = []
        
        # rho_diffã®è¨ˆç®—åˆ¶ç´„ã‚’è¿½åŠ ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°è€ƒæ…®ï¼‰
        rho_expr = cp.Constant(np.zeros(grid_shape))
        for i in range(n):
            for j in range(n):
                # basisã‚‚ãƒ‡ãƒ¼ã‚¿ã‚¹ã‚±ãƒ¼ãƒ«ã§æ­£è¦åŒ–
                # è¤‡ç´ æ•°è¡Œåˆ—ã®å ´åˆã€å®Ÿéƒ¨ã®ã¿ã‚’ä½¿ç”¨ï¼ˆå¯†åº¦ã¯å®Ÿæ•°ã®ãŸã‚ï¼‰
                basis_scaled = basis[i, j, :, :, :] / data_scale
                if np.iscomplexobj(basis_scaled):
                    rho_expr += cp.real(P[i, j] * cp.Constant(basis_scaled))
                else:
                    rho_expr += cp.real(P[i, j]) * cp.Constant(basis_scaled)
        
        constraints.append(rho_diff == rho_expr - cp.Constant(scaled_target))
        
        # åŠæ­£å®šå€¤åˆ¶ç´„
        constraints.append(P >> 0)  # P ã¯åŠæ­£å®šå€¤
        
        # ã‚¼ãƒ­åˆ¶ç´„ã®è¿½åŠ 
        if zero_constraints is not None:
            for row, col in zero_constraints:
                constraints.append(P[row, col] == 0)
            print(f"ã‚¼ãƒ­åˆ¶ç´„ã‚’è¿½åŠ ã—ã¾ã—ãŸ: {len(set(zero_constraints))}å€‹ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæˆåˆ†")
        
        # ç›®çš„é–¢æ•°: ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã‚ŒãŸé‡ã¿ä»˜ãäºŒä¹—èª¤å·® + æ­£å‰‡åŒ–é …
        weighted_diff = cp.multiply(cp.Constant(np.sqrt(scaled_weights)), rho_diff)
        
        # ã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ã•ã‚ŒãŸç›®çš„é–¢æ•°ï¼ˆå€¤ã‚’é©åº¦ãªç¯„å›²ã«ä¿ã¤ï¼‰
        objective_scale = max(1.0, 1.0 / (data_scale * weight_scale))
        objective = objective_scale * cp.sum_squares(weighted_diff) / cp.Constant(np.prod(grid_shape))
        
        if regularization_lambda > 0:
            # æ­£å‰‡åŒ–é …ã‚‚ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’è€ƒæ…®
            reg_scale = regularization_lambda * (data_scale ** 2)
            objective += reg_scale * cp.sum_squares(P)
        
        print(f"Objective scaling factor: {objective_scale:.2e}")
        print(f"Expected objective magnitude: O({objective_scale * data_scale * weight_scale:.1e})")
        
        # å•é¡Œã®å®šç¾©
        problem = cp.Problem(cp.Minimize(objective), constraints)
        
        # æœ€é©åŒ–ã®å®Ÿè¡Œ
        print("CVXPYæœ€é©åŒ–ã‚’å®Ÿè¡Œä¸­...")
        try:
            # ã¾ãšMOSEKã‚’è©¦ã™ï¼ˆå³ã—ã„åæŸæ¡ä»¶ï¼‰
            problem.solve(
                solver=cp.MOSEK, 
                verbose=True,
                mosek_params={
                    'MSK_DPAR_INTPNT_CO_TOL_PFEAS': 1e-10,
                    'MSK_DPAR_INTPNT_CO_TOL_DFEAS': 1e-10,
                    'MSK_DPAR_INTPNT_CO_TOL_REL_GAP': 1e-10,
                    'MSK_DPAR_INTPNT_CO_TOL_MU_RED': 1e-12
                }
            )
        except:
            try:
                # MOSEKãŒå¤±æ•—ã—ãŸå ´åˆã¯SCSã‚’è©¦ã™ï¼ˆå³ã—ã„åæŸæ¡ä»¶ï¼‰
                error_handler.handle(
                    "MOSEKã‚½ãƒ«ãƒãƒ¼ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚SCSã‚½ãƒ«ãƒãƒ¼ã‚’ä½¿ç”¨ã—ã¾ã™",
                    ErrorCode.NOT_FOUND,
                    ErrorLevel.WARNING
                )
                problem.solve(
                    solver=cp.SCS, 
                    verbose=True,
                    eps_abs=1e-8,      # å®Ÿç”¨çš„ãªçµ¶å¯¾è¨±å®¹èª¤å·®ï¼ˆMSE 1e-4ã«å¯¾å¿œï¼‰
                    eps_rel=1e-8,      # å®Ÿç”¨çš„ãªç›¸å¯¾è¨±å®¹èª¤å·®
                    max_iters=3000,    # ååˆ†ãªåå¾©æ•°ã‚’ç¢ºä¿
                    alpha=1.5,         # Douglas-Rachfordç·©å’Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
                    scale=0.01,        # åŒå¯¾ã‚¹ã‚±ãƒ¼ãƒ«å› å­ï¼ˆå°ã•ã„ç›®çš„é–¢æ•°å€¤ã«é©å¿œï¼‰
                    adaptive_scale=True, # é©å¿œçš„ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
                    normalize=True,    # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†æ­£è¦åŒ–ã‚’æœ‰åŠ¹åŒ–
                    acceleration_lookback=10,  # AndersonåŠ é€Ÿã®ãƒ¡ãƒ¢ãƒªã‚’é©åº¦ã«è¨­å®š
                    # å®Ÿç”¨çš„åæŸã®ãŸã‚ã®è¿½åŠ è¨­å®š
                    time_limit_secs=300.0,  # 5åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                    use_indirect=False  # ç›´æ¥æ³•ã‚’ä½¿ç”¨ï¼ˆã‚ˆã‚Šå®‰å®šï¼‰
                )
            except Exception as e:
                error = error_handler.handle(
                    f"æœ€é©åŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}",
                    ErrorCode.VALIDATION,
                    ErrorLevel.CRITICAL
                )
                if error:
                    raise error
        
        # çµæœã®ç¢ºèª
        if problem.status not in ["infeasible", "unbounded"]:
            if problem.status != "optimal":
                error_handler.handle(
                    f"æœ€é©åŒ–ãŒæœ€é©è§£ã«åæŸã—ã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {problem.status}",
                    ErrorCode.VALIDATION,
                    ErrorLevel.WARNING
                )
            
            # çµæœã®å–å¾—
            P_optimal = P.value
            if P_optimal is None:
                error = error_handler.handle(
                    "æœ€é©åŒ–çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ",
                    ErrorCode.VALIDATION,
                    ErrorLevel.CRITICAL
                )
                if error:
                    raise error
            
            print(f"æœ€é©åŒ–å®Œäº†ã€‚ç›®çš„é–¢æ•°å€¤: {objective.value}")
            
            # rhoã®è¨ˆç®—ï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’è€ƒæ…®ã—ãŸé€†å¤‰æ›ï¼‰
            rho_output = np.zeros(grid_shape)
            for i in range(n):
                for j in range(n):
                    # å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
                    rho_output += (P_optimal[i, j] * basis[i, j, :, :, :]).real
            
            # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
            os.makedirs("output", exist_ok=True)
            
            # rho_output.xplorã®ä¿å­˜
            make_xplor(rho_output, "output/rho_output.xplor", "rho_output", settings)
            print("rho_output.xplorã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            
            # è¤‡ç´ æ•°è¡Œåˆ—ã®ä¿å­˜ï¼ˆå®Ÿéƒ¨ã¨è™šéƒ¨ã‚’åˆ†ã‘ã¦ä¿å­˜ï¼‰
            P_real = np.real(P_optimal)
            P_imag = np.imag(P_optimal)
            
            # å®Ÿéƒ¨ã‚’ä¿å­˜
            P_real_df = pd.DataFrame(P_real)
            P_real_df.to_csv("output/matrix_real.csv", index=False)
            print("matrix_real.csvã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            
            # è™šéƒ¨ã‚’ä¿å­˜ï¼ˆã‚¼ãƒ­ã§ãªã„å ´åˆã®ã¿ï¼‰
            if np.max(np.abs(P_imag)) > 1e-12:
                P_imag_df = pd.DataFrame(P_imag)
                P_imag_df.to_csv("output/matrix_imag.csv", index=False)
                print("matrix_imag.csvã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            else:
                print("è™šéƒ¨ã¯ã‚¼ãƒ­ã®ãŸã‚ã€matrix_imag.csvã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            
            # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€å®Ÿéƒ¨ã®ã¿ã‚’matrix.csvã¨ã—ã¦ã‚‚ä¿å­˜
            P_real_df.to_csv("output/matrix.csv", index=False)
            print("å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€å®Ÿéƒ¨ã‚’matrix.csvã¨ã—ã¦ã‚‚ä¿å­˜ã—ã¾ã—ãŸ")
            
            # çµ±è¨ˆæƒ…å ±ã®å‡ºåŠ›ï¼ˆå…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã§è©•ä¾¡ï¼‰
            rms_error = np.sqrt(np.mean((rho_output - target_data) ** 2))
            relative_error = rms_error / np.sqrt(np.mean(target_data ** 2))
            print(f"RMSèª¤å·®: {rms_error:.6e}")
            print(f"ç›¸å¯¾RMSèª¤å·®: {relative_error:.6e}")
            
            # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã•ã‚ŒãŸèª¤å·®ã‚‚è¡¨ç¤º
            scaled_residual = np.sqrt(np.mean(((rho_output / data_scale) - scaled_target) ** 2))
            print(f"ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¾Œã®RMSèª¤å·®: {scaled_residual:.6e}")
            
            # åæŸè¨ºæ–­æƒ…å ±ã®è¿½åŠ 
            if hasattr(problem, 'solver_stats') and problem.solver_stats is not None:
                stats = problem.solver_stats
                print(f"\n=== åæŸè¨ºæ–­ ===")
                print(f"ã‚½ãƒ«ãƒãƒ¼: {stats.solver_name if hasattr(stats, 'solver_name') else 'SCS'}")
                print(f"åå¾©å›æ•°: {stats.num_iters if hasattr(stats, 'num_iters') else 'N/A'}")
                print(f"è§£æ³•æ™‚é–“: {stats.solve_time:.3f}ç§’" if hasattr(stats, 'solve_time') else "è§£æ³•æ™‚é–“: N/A")
                
                # SCSç‰¹æœ‰ã®æƒ…å ±
                if hasattr(stats, 'extra_stats') and stats.extra_stats:
                    extra = stats.extra_stats
                    if 'residual_norm' in extra:
                        print(f"æœ€çµ‚æ®‹å·®ãƒãƒ«ãƒ : {extra['residual_norm']:.2e}")
                    if 'gap' in extra:
                        print(f"åŒå¯¾ã‚®ãƒ£ãƒƒãƒ—: {extra['gap']:.2e}")
            
            # è¡Œåˆ—Pã®æ€§è³ªã‚’ç¢ºèªï¼ˆè¤‡ç´ ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆè¡Œåˆ—å¯¾å¿œï¼‰
            eigenvalues = np.linalg.eigvals(P_optimal)
            # ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆè¡Œåˆ—ã®å›ºæœ‰å€¤ã¯å®Ÿæ•°ãªã®ã§å®Ÿéƒ¨ã‚’å–å¾—
            eigenvalues_real = np.real(eigenvalues)
            eigenvalues_sorted = np.sort(eigenvalues_real)[::-1]
            min_eigenvalue = np.min(eigenvalues_real)
            condition_number = np.max(eigenvalues_real) / max(min_eigenvalue, 1e-12)
            
            print(f"\n=== è¤‡ç´ ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆè¡Œåˆ—P ã®æ€§è³ª ===")
            print(f"æœ€å°å›ºæœ‰å€¤: {min_eigenvalue:.2e}")
            print(f"æœ€å¤§å›ºæœ‰å€¤: {np.max(eigenvalues_real):.2e}")
            print(f"æ¡ä»¶æ•°: {condition_number:.2e}")
            print(f"æœ‰åŠ¹ãƒ©ãƒ³ã‚¯ (é–¾å€¤1e-8): {np.sum(eigenvalues_real > 1e-8)}")
            print(f"ä¸Šä½5å›ºæœ‰å€¤: {eigenvalues_sorted[:5]}")
            
            # ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆæ€§ã®ç¢ºèª
            hermitian_error = np.max(np.abs(P_optimal - P_optimal.conj().T))
            print(f"ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆæ€§èª¤å·®: {hermitian_error:.2e}")
            
            # PSDåˆ¶ç´„ã®è©•ä¾¡ï¼ˆæ•°å€¤è¨±å®¹èª¤å·®ã‚’è€ƒæ…®ï¼‰
            psd_tolerance = 1e-6  # æ•°å€¤èª¤å·®ã®è¨±å®¹ç¯„å›²
            if min_eigenvalue < -psd_tolerance:
                error_handler.handle(
                    f"çµæœã®è¡Œåˆ—ãŒåŠæ­£å®šå€¤ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚æœ€å°å›ºæœ‰å€¤: {min_eigenvalue}",
                    ErrorCode.VALIDATION,
                    ErrorLevel.WARNING
                )
                
                # PSDä¿®æ­£ã®ææ¡ˆ
                print(f"\nğŸ”§ PSDä¿®æ­£ã‚ªãƒ—ã‚·ãƒ§ãƒ³:")
                print(f"   - è² ã®å›ºæœ‰å€¤ã‚’0ã«ã‚¯ãƒªãƒƒãƒ—")
                print(f"   - æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å¢—åŠ  (ç¾åœ¨: {regularization_lambda})")
                
                # è‡ªå‹•PSDä¿®æ­£ï¼ˆè¤‡ç´ ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆè¡Œåˆ—å¯¾å¿œï¼‰
                if abs(min_eigenvalue) < 1e-3:  # å°ã•ã„è² ã®å›ºæœ‰å€¤ãªã‚‰è‡ªå‹•ä¿®æ­£
                    eigenvalues_corrected = np.maximum(eigenvalues_real, 0)
                    eigenvecs = np.linalg.eigh(P_optimal)[1]
                    P_corrected = eigenvecs @ np.diag(eigenvalues_corrected) @ eigenvecs.conj().T
                    
                    # ä¿®æ­£å¾Œã®ä¿å­˜ï¼ˆå®Ÿéƒ¨ã¨è™šéƒ¨ã‚’åˆ†ã‘ã¦ä¿å­˜ï¼‰
                    P_corrected_real = np.real(P_corrected)
                    P_corrected_imag = np.imag(P_corrected)
                    
                    # å®Ÿéƒ¨ã‚’ä¿å­˜
                    P_corrected_real_df = pd.DataFrame(P_corrected_real)
                    P_corrected_real_df.to_csv("output/matrix_psd_corrected_real.csv", index=False)
                    
                    # è™šéƒ¨ã‚’ä¿å­˜ï¼ˆã‚¼ãƒ­ã§ãªã„å ´åˆã®ã¿ï¼‰
                    if np.max(np.abs(P_corrected_imag)) > 1e-12:
                        P_corrected_imag_df = pd.DataFrame(P_corrected_imag)
                        P_corrected_imag_df.to_csv("output/matrix_psd_corrected_imag.csv", index=False)
                        print(f"   âœ“ PSDä¿®æ­£æ¸ˆã¿è¡Œåˆ—ï¼ˆå®Ÿéƒ¨ï¼‰ã‚’ matrix_psd_corrected_real.csv ã«ä¿å­˜")
                        print(f"   âœ“ PSDä¿®æ­£æ¸ˆã¿è¡Œåˆ—ï¼ˆè™šéƒ¨ï¼‰ã‚’ matrix_psd_corrected_imag.csv ã«ä¿å­˜")
                    else:
                        print(f"   âœ“ PSDä¿®æ­£æ¸ˆã¿è¡Œåˆ—ï¼ˆå®Ÿéƒ¨ã®ã¿ï¼‰ã‚’ matrix_psd_corrected_real.csv ã«ä¿å­˜")
                    
                    print(f"   ä¿®æ­£å¾Œã®æœ€å°å›ºæœ‰å€¤: {np.min(eigenvalues_corrected):.2e}")
            else:
                print(f"âœ“ è¡Œåˆ—ã¯åŠæ­£å®šå€¤ã§ã™ï¼ˆè¨±å®¹èª¤å·® {psd_tolerance:.1e} å†…ï¼‰")
            
            # åæŸã«é–¢ã™ã‚‹è¿½åŠ ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹
            if relative_error > target_relative_error:
                print(f"\nâš ï¸  ç›¸å¯¾èª¤å·®ãŒç›®æ¨™å€¤ã‚’è¶…ãˆã¦ã„ã¾ã™ï¼ˆ{relative_error:.1e} > {target_relative_error:.1e}ï¼‰")
                print("   æ¨å¥¨å¯¾ç­–:")
                print(f"   - æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´: {regularization_lambda} â†’ {regularization_lambda * 10}")
                print(f"   - ã‚ˆã‚Šå¤šãã®åå¾©å›æ•°: {2000} â†’ {4000}")
                print(f"   - ã‚ˆã‚Šå³ã—ã„è¨±å®¹èª¤å·®: eps_abs={1e-4} â†’ {1e-5}")
            elif rms_error < target_mse:
                print(f"\nâœ“ MSEç›®æ¨™é”æˆ: {rms_error:.1e} < {target_mse:.1e}")
                print("   å®Ÿç”¨çš„ã«ã¯ååˆ†ãªç²¾åº¦ã§ã™ã€‚")
            
            # å®Ÿç”¨æ€§ã®ç·åˆåˆ¤å®š
            is_practically_converged = (
                rms_error < target_mse and 
                relative_error < target_relative_error and
                abs(min_eigenvalue) < 1e-3
            )
            
            if is_practically_converged:
                print(f"\nğŸ¯ å®Ÿç”¨çš„åæŸé”æˆ!")
                print(f"   - MSE: {rms_error:.1e} < {target_mse:.1e} âœ“")
                print(f"   - ç›¸å¯¾èª¤å·®: {relative_error:.1e} < {target_relative_error:.1e} âœ“") 
                print(f"   - PSDåˆ¶ç´„: |æœ€å°å›ºæœ‰å€¤| = {abs(min_eigenvalue):.1e} < 1e-3 âœ“")
            else:
                print(f"\nâš ï¸  å®Ÿç”¨çš„åæŸæœªé”æˆã€‚ã•ã‚‰ãªã‚‹èª¿æ•´ãŒå¿…è¦ã§ã™ã€‚")
            
        else:
            error = error_handler.handle(
                f"æœ€é©åŒ–å•é¡ŒãŒè§£ã‘ã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {problem.status}",
                ErrorCode.VALIDATION,
                ErrorLevel.CRITICAL
            )
            if error:
                raise error
                
    except Exception as e:
        error = error_handler.handle(
            f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}",
            ErrorCode.VALIDATION,
            ErrorLevel.CRITICAL
        )
        if error:
            raise error


def run_practical_optimization(
    basis: np.ndarray, 
    target_data: np.ndarray, 
    settings: Settings,
    **kwargs
) -> dict:
    """
    å®Ÿç”¨çš„ãªSDPæœ€é©åŒ–ã®å®Ÿè¡Œ
    
    MSE 1e-3ä»¥ä¸‹ã€ç›¸å¯¾èª¤å·®5%ä»¥ä¸‹ã‚’ç›®æ¨™ã¨ã—ãŸå®Ÿç”¨çš„ãªè¨­å®šã§æœ€é©åŒ–ã‚’å®Ÿè¡Œ
    
    Args:
        basis: åŸºåº•é–¢æ•°é…åˆ—
        target_data: ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒ‡ãƒ¼ã‚¿
        settings: è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
        **kwargs: main_loop_cvxpyã«æ¸¡ã•ã‚Œã‚‹è¿½åŠ å¼•æ•°
                 ä¾‹: zero_constraints=[(0,3), (3,0)] ã§ç‰¹å®šæˆåˆ†ã‚’0ã«å›ºå®š
    
    Returns:
        dict: æœ€é©åŒ–çµæœã®è¦ç´„
    """
    print("=== å®Ÿç”¨çš„SDPæœ€é©åŒ–ã®å®Ÿè¡Œ ===")
    print("ç›®æ¨™: MSE < 1e-3, ç›¸å¯¾èª¤å·® < 5%")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
    default_kwargs = {
        'regularization_lambda': 1e-6,
        'target_mse': 1e-3,
        'target_relative_error': 0.05,
        'initial_method': 'identity'
    }
    default_kwargs.update(kwargs)
    
    try:
        main_loop_cvxpy(basis, target_data, settings, **default_kwargs)
        
        # çµæœã®èª­ã¿è¾¼ã¿ã¨è©•ä¾¡ï¼ˆè¤‡ç´ æ•°å¯¾å¿œï¼‰
        if os.path.exists("output/matrix_real.csv"):
            P_real = pd.read_csv("output/matrix_real.csv", header=None).values
            
            # è™šéƒ¨ã®èª­ã¿è¾¼ã¿ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
            if os.path.exists("output/matrix_imag.csv"):
                P_imag = pd.read_csv("output/matrix_imag.csv", header=None).values
                P_result = P_real + 1j * P_imag
                print("è¤‡ç´ æ•°è¡Œåˆ—ã¨ã—ã¦çµæœã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            else:
                P_result = P_real.astype(complex)
                print("å®Ÿæ•°è¡Œåˆ—ã¨ã—ã¦çµæœã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
            
            eigenvals = np.linalg.eigvals(P_result)
            eigenvals_real = np.real(eigenvals)  # ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆè¡Œåˆ—ã®å›ºæœ‰å€¤ã¯å®Ÿæ•°
            
            result_summary = {
                'success': True,
                'min_eigenvalue': np.min(eigenvals_real),
                'max_eigenvalue': np.max(eigenvals_real),
                'rank': np.sum(eigenvals_real > 1e-8),
                'condition_number': np.max(eigenvals_real) / max(np.min(eigenvals_real), 1e-12),
                'psd_corrected_available': os.path.exists("output/matrix_psd_corrected_real.csv"),
                'is_complex': np.max(np.abs(np.imag(P_result))) > 1e-12
            }
            
            print(f"\n=== æœ€é©åŒ–çµæœè¦ç´„ ===")
            print(f"æˆåŠŸ: {result_summary['success']}")
            print(f"æœ‰åŠ¹ãƒ©ãƒ³ã‚¯: {result_summary['rank']}")
            print(f"PSDä¿®æ­£ç‰ˆåˆ©ç”¨å¯èƒ½: {result_summary['psd_corrected_available']}")
            
            return result_summary
        else:
            return {'success': False, 'error': 'Output file not found'}
            
    except Exception as e:
        return {'success': False, 'error': str(e)}


# ä½¿ç”¨ä¾‹
"""
å®Ÿç”¨çš„ãªä½¿ç”¨æ–¹æ³•:

1. åŸºæœ¬çš„ãªå®Ÿè¡Œ:
   result = run_practical_optimization(basis, target_data, settings)

2. æ­£å‰‡åŒ–ã‚’å¼·åŒ–:
   result = run_practical_optimization(
       basis, target_data, settings, 
       regularization_lambda=1e-5
   )

3. ã‚ˆã‚Šå³ã—ã„ç›®æ¨™è¨­å®š:
   result = run_practical_optimization(
       basis, target_data, settings,
       target_mse=1e-4,
       target_relative_error=0.01
   )

4. ç‰¹å®šæˆåˆ†ã‚’ã‚¼ãƒ­ã«å›ºå®š:
   # ä¾‹ï¼šs-dæ··æˆã‚’ç¦æ­¢ (4s=0, 3d=1,2,3,4,5ãªã‚‰)
   zero_constraints = [(0,1), (0,2), (0,3), (0,4), (0,5)]
   result = run_practical_optimization(
       basis, target_data, settings,
       zero_constraints=zero_constraints
   )

çµæœã®ä½¿ç”¨ï¼ˆè¤‡ç´ æ•°ã‚¨ãƒ«ãƒŸãƒ¼ãƒˆè¡Œåˆ—å¯¾å¿œï¼‰:
- matrix_real.csv: æœ€é©åŒ–çµæœã®å®Ÿéƒ¨
- matrix_imag.csv: æœ€é©åŒ–çµæœã®è™šéƒ¨ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
- matrix.csv: å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®å®Ÿéƒ¨ã®ã¿ï¼ˆå¾“æ¥å½¢å¼ï¼‰
- matrix_psd_corrected_real.csv: PSDä¿®æ­£æ¸ˆã¿å®Ÿéƒ¨ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
- matrix_psd_corrected_imag.csv: PSDä¿®æ­£æ¸ˆã¿è™šéƒ¨ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
"""


def generate_orbital_blocking_constraints(
    orbital_types: list[str], 
    blocked_interactions: list[tuple[str, str]]
) -> list[tuple[int, int]]:
    """
    è»Œé“ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦ã‚¼ãƒ­åˆ¶ç´„ã‚’ç”Ÿæˆ
    
    Args:
        orbital_types: è»Œé“ã‚¿ã‚¤ãƒ—ã®ãƒªã‚¹ãƒˆ ä¾‹: ['4s', '4px', '4py', '4pz', '3dxy', '3dyz', '3dxz', '3dx2-y2', '3dz2']
        blocked_interactions: ç¦æ­¢ã™ã‚‹ç›¸äº’ä½œç”¨ã®ãƒªã‚¹ãƒˆ ä¾‹: [('4s', '3d'), ('4p', '3d')]
    
    Returns:
        ã‚¼ãƒ­åˆ¶ç´„ã®ãƒªã‚¹ãƒˆ [(i,j), ...]
    
    Examples:
        # s-dæ··æˆã‚’ç¦æ­¢
        orbital_types = ['4s', '4px', '4py', '4pz', '3dxy', '3dyz', '3dxz', '3dx2-y2', '3dz2']
        blocked = [('4s', '3d')]
        constraints = generate_orbital_blocking_constraints(orbital_types, blocked)
        
        # s-pæ··æˆã¨s-dæ··æˆã‚’ç¦æ­¢  
        blocked = [('4s', '4p'), ('4s', '3d')]
        constraints = generate_orbital_blocking_constraints(orbital_types, blocked)
    """
    zero_constraints = []
    
    for orb1_pattern, orb2_pattern in blocked_interactions:
        for i, orb1 in enumerate(orbital_types):
            for j, orb2 in enumerate(orbital_types):
                # ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
                if (orb1_pattern in orb1 and orb2_pattern in orb2) or \
                   (orb1_pattern in orb2 and orb2_pattern in orb1):
                    if i != j:  # å¯¾è§’æˆåˆ†ã¯é™¤å¤–ï¼ˆè‡ªå·±ç›¸äº’ä½œç”¨ã¯è¨±å¯ï¼‰
                        zero_constraints.append((i, j))
    
    # é‡è¤‡ã‚’é™¤å»
    zero_constraints = list(set(zero_constraints))
    
    print(f"ç”Ÿæˆã•ã‚ŒãŸã‚¼ãƒ­åˆ¶ç´„: {len(zero_constraints)}å€‹")
    for i, j in zero_constraints:
        print(f"  P[{i},{j}] = 0  ({orbital_types[i]} - {orbital_types[j]})")
    
    return zero_constraints


def generate_symmetry_based_constraints(
    orbital_quantum_numbers: list[tuple[int, int, int]],
    forbidden_transitions: list[tuple[tuple[int, int, int], tuple[int, int, int]]] = None
) -> list[tuple[int, int]]:
    """
    é‡å­æ•°ã«åŸºã¥ãå¯¾ç§°æ€§åˆ¶ç´„ã‚’ç”Ÿæˆ
    
    Args:
        orbital_quantum_numbers: [(n,l,m), ...] ã®é‡å­æ•°ãƒªã‚¹ãƒˆ
        forbidden_transitions: ç¦æ­¢é·ç§»ã®ãƒªã‚¹ãƒˆ [((n1,l1,m1), (n2,l2,m2)), ...]
    
    Returns:
        ã‚¼ãƒ­åˆ¶ç´„ã®ãƒªã‚¹ãƒˆ
        
    Examples:
        # Fe ã® 4s, 4p, 3dè»Œé“
        quantum_numbers = [
            (4,0,0),     # 4s
            (4,1,-1), (4,1,0), (4,1,1),  # 4p
            (3,2,-2), (3,2,-1), (3,2,0), (3,2,1), (3,2,2)  # 3d
        ]
        
        # s-dç›´æ¥æ··æˆã‚’ç¦æ­¢ (é¸æŠå‰‡: Î”l = Â±1)
        forbidden = [
            ((4,0,0), (3,2,-2)), ((4,0,0), (3,2,-1)), 
            ((4,0,0), (3,2,0)), ((4,0,0), (3,2,1)), ((4,0,0), (3,2,2))
        ]
        constraints = generate_symmetry_based_constraints(quantum_numbers, forbidden)
    """
    zero_constraints = []
    
    if forbidden_transitions is not None:
        for qn1, qn2 in forbidden_transitions:
            try:
                i = orbital_quantum_numbers.index(qn1)
                j = orbital_quantum_numbers.index(qn2)
                zero_constraints.append((i, j))
                if i != j:
                    zero_constraints.append((j, i))  # å¯¾ç§°æ€§
            except ValueError:
                print(f"è­¦å‘Š: é‡å­æ•° {qn1} ã¾ãŸã¯ {qn2} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    # è‡ªå‹•çš„ãªé¸æŠå‰‡é©ç”¨ï¼ˆä¾‹ï¼šÎ”l â‰  Â±1ã®é·ç§»ã‚’ç¦æ­¢ï¼‰
    # ã“ã®éƒ¨åˆ†ã¯å¿…è¦ã«å¿œã˜ã¦ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
    
    print(f"å¯¾ç§°æ€§ãƒ™ãƒ¼ã‚¹ã®ã‚¼ãƒ­åˆ¶ç´„: {len(zero_constraints)}å€‹")
    return list(set(zero_constraints))


# å…·ä½“çš„ãªä½¿ç”¨ä¾‹
"""
# Feç³»ã§ã®å…¸å‹çš„ãªä½¿ç”¨ä¾‹:

# 1. è»Œé“åãƒ™ãƒ¼ã‚¹ã§ã®åˆ¶ç´„
orbital_names = ['4s', '4px', '4py', '4pz', '3dxy', '3dyz', '3dxz', '3dx2-y2', '3dz2']

# s-dæ··æˆã®ã¿ç¦æ­¢
zero_constraints = generate_orbital_blocking_constraints(
    orbital_names, [('4s', '3d')]
)

# 2. é‡å­æ•°ãƒ™ãƒ¼ã‚¹ã§ã®åˆ¶ç´„  
quantum_numbers = [
    (4,0,0),     # 4s
    (4,1,-1), (4,1,0), (4,1,1),  # 4p
    (3,2,-2), (3,2,-1), (3,2,0), (3,2,1), (3,2,2)  # 3d
]

forbidden_transitions = [
    ((4,0,0), (3,2,m)) for m in [-2,-1,0,1,2]  # s-dç›´æ¥é·ç§»ã‚’ç¦æ­¢
]

zero_constraints = generate_symmetry_based_constraints(
    quantum_numbers, forbidden_transitions
)

# 3. æœ€é©åŒ–ã®å®Ÿè¡Œ
result = run_practical_optimization(
    basis, target_data, settings,
    zero_constraints=zero_constraints,
    regularization_lambda=1e-6
)
"""
    
    